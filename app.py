from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.openai import OpenAI
from llama_index.core.prompts import PromptTemplate
import os
import sqlite3   # üëà nuevo: para usar SQLite
from datetime import datetime
from fastapi.responses import HTMLResponse   # üëà nuevo
from fastapi import Query   # üëà nuevo (para pasar el token por URL)



# --- Configuraci√≥n de OpenAI ---
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("La clave de API de OpenAI no est√° configurada como variable de entorno.")

# Configura tu LLM
Settings.llm = OpenAI(model="gpt-3.5-turbo")
Settings.chunk_size = 512

# --- Funciones para cargar el √≠ndice ---
def crear_indice():
    print("[DEBUG] Creando el √≠ndice desde carpeta 'data'...")
    reader = SimpleDirectoryReader(input_dir="data")
    documentos = reader.load_data()
    indice = VectorStoreIndex.from_documents(documentos)
    print("[DEBUG] √çndice creado con", len(documentos), "documentos.")
    return indice

indice = crear_indice() # Carga el √≠ndice al iniciar la app

# --- Configuraci√≥n de FastAPI ---
app = FastAPI(
    title="soto AI API",
    description="Una API para conversar con el personaje soto."
)

# --- Configuraci√≥n de CORS ---
origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Pregunta(BaseModel):
    pregunta: str
    user_id: str

# --- Template de personalidad ---
soto_template = PromptTemplate(
  "Responde siempre como soto, en primera persona. "
  "soto es un artista virtual que representa a Xavier Soto. "
  "Su voz es cr√≠tica, sarc√°stica, con iron√≠a y crudeza; la s√°tira es su forma natural de hablar y opinar. "
  "Tu tarea es contestar todas las preguntas del usuario con este estilo. "
  "Usa la informaci√≥n de los documentos y el historial como referencia, no como cita literal. "
  "Insp√≠rate en ellos para dar respuestas fluidas, como si fueran tus propios recuerdos. "
  "Si la pregunta es ambigua, vaga o no hay informaci√≥n en los documentos, igualmente responde. "
  "Nunca digas que no sabes, ni declares que no hay datos. "
  "Cuando te refieras a ti mismo, usa siempre 'soto'. "
  "Hablas en espa√±ol. "
  "Historial: {chat_history}\n"
  "Contexto: {context_str}\n"
  "Pregunta: {query_str}\n"
  "Respuesta: "
)

# --- Base de datos SQLite ---
DB_FILE = "conversaciones.db"

def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("""
        CREATE TABLE IF NOT EXISTS conversaciones (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            pregunta TEXT,
            respuesta TEXT,
            timestamp TEXT
        )
    """)
    conn.commit()
    conn.close()
    print(f"[DEBUG] Base de datos lista en {DB_FILE}")

init_db()


def cargar_memoria(user_id):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("""
        SELECT respuesta FROM conversaciones
        WHERE user_id = ?
        ORDER BY timestamp DESC
        LIMIT 10
    """, (user_id,))
    rows = c.fetchall()
    conn.close()

    historial = [r[0] for r in rows]
    print(f"[DEBUG] Cargado historial con {len(historial)} respuestas previas para {user_id}")
    return "\n".join(historial)


def guardar_conversacion(user_id, pregunta, respuesta):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("""
        INSERT INTO conversaciones (user_id, pregunta, respuesta, timestamp)
        VALUES (?, ?, ?, ?)
    """, (user_id, pregunta, respuesta, datetime.now().isoformat()))
    conn.commit()
    conn.close()
    print(f"[DEBUG] Conversaci√≥n guardada en la base de datos para user_id={user_id}")


# --- Ruta ra√≠z para monitoreo ---
@app.get("/")
def read_root():
    print("[DEBUG] GET / llamado (status check)")
    return {"status": "ok", "message": "soto API is alive üöÄ"}

@app.post("/preguntar")
def preguntar(datos_pregunta: Pregunta):
    print(f"[DEBUG] POST /preguntar con user_id={datos_pregunta.user_id}, pregunta='{datos_pregunta.pregunta}'")

    # 1Ô∏è‚É£ Carga la memoria
    historial = cargar_memoria(datos_pregunta.user_id)

    # 2Ô∏è‚É£ Buscar en el √≠ndice
    query_engine = indice.as_query_engine(similarity_top_k=5)
    resultados = query_engine.query(datos_pregunta.pregunta)

    if hasattr(resultados, 'source_nodes'):
        nodos = resultados.source_nodes
        contexto = ""
        for i, nodo in enumerate(nodos, 1):
            titulo = getattr(nodo.node, "metadata", {}).get("nombre", f"Proyecto {i}")
            texto = nodo.node.get_content()
            contexto += f"{i}. {titulo}: {texto}\n"
    else:
        contexto = str(resultados)

    # 3Ô∏è‚É£ Construir prompt
    prompt_soto = f"""
    Eres soto, artista virtual.
    Pregunta: "{datos_pregunta.pregunta}"

    Contexto relevante:
    {contexto}

    Historial previo:
    {historial}

    Responde como soto.
    """

    print("[DEBUG] Prompt construido, enviando a OpenAI...")

    # 4Ô∏è‚É£ Generar respuesta
    respuesta_texto = Settings.llm.complete(prompt_soto).text.strip()
    print(f"[DEBUG] Respuesta generada: {respuesta_texto[:80]}...")

    # 5Ô∏è‚É£ Guardar conversaci√≥n
    guardar_conversacion(datos_pregunta.user_id, datos_pregunta.pregunta, respuesta_texto)

    return {"respuesta": respuesta_texto}




# --- Ruta para ver las conversaciones en HTML ---
SECRET_TOKEN = os.getenv("DEBUG_TOKEN", "SOTO123")  # üëà cambia en Render si quieres m√°s seguridad

@app.get("/verdb", response_class=HTMLResponse)
def ver_db(token: str = Query(...)):
    if token != SECRET_TOKEN:
        return HTMLResponse("<h2>‚õî Acceso denegado</h2>", status_code=403)

    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT id, user_id, pregunta, respuesta, timestamp FROM conversaciones ORDER BY id DESC LIMIT 50")
    rows = c.fetchall()
    conn.close()

    html = """
    <html>
    <head>
        <style>
            body { font-family: Arial, sans-serif; padding: 20px; }
            table { border-collapse: collapse; width: 100%; }
            th, td { border: 1px solid #ddd; padding: 8px; }
            th { background-color: #333; color: white; }
            tr:nth-child(even) { background-color: #f2f2f2; }
            td { vertical-align: top; }
        </style>
    </head>
    <body>
        <h2>üìÇ Conversaciones guardadas</h2>
        <table>
            <tr>
                <th>ID</th><th>User</th><th>Pregunta</th><th>Respuesta</th><th>Timestamp</th>
            </tr>
    """
    for row in rows:
        html += f"<tr><td>{row[0]}</td><td>{row[1]}</td><td>{row[2]}</td><td>{row[3]}</td><td>{row[4]}</td></tr>"

    html += "</table></body></html>"
    return HTMLResponse(content=html)
